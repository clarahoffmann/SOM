{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScrapeTweet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oZUzI7vBQUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "import csv\n",
        "import datetime\n",
        "import numpy\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeR-Hb-PCEHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Twitter API credentials\n",
        "consumer_key = \"yU6zvHRJeuram1SjoP1MLM4Cv\"\n",
        "consumer_secret = \"jsheyJjVfuhA6abQ4aWyYPq1qyZi6vvH28RBlV4kBbD4Tbv1Vp\"\n",
        "access_key = \"4717262001-OjnuQx0EHS9cfglFG4AevWL7RJsGA9TkwjhPOPn\"\n",
        "access_secret = \"bXOoR2E6MsJVMLz4rhvNQkUwURS9aZg9UbcqZNY90FVxP\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6VxbmmOIbVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_key, access_secret)\n",
        "api = tweepy.API(auth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQQAA2wgZbTp",
        "colab_type": "text"
      },
      "source": [
        "Now we scrape the tweets that we need. At the moment we only get the last 30 tweets but another timeframe might be interesting: f.e. right before and after the European Election and then see if more similar before or afterwards"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt7sijbdJnod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startDate = datetime.datetime(2019, 5, 10, 0, 0, 0)\n",
        "endDate = datetime.datetime(2019, 5, 25, 0, 0, 0)\n",
        "\n",
        "# Function to extract tweets \n",
        "def get_tweets(username, realname, party): \n",
        "          \n",
        "        # Authorization to consumer key and consumer secret \n",
        "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
        "  \n",
        "        # Access to user's access key and access secret \n",
        "        auth.set_access_token(access_key, access_secret) \n",
        "  \n",
        "        # Calling api \n",
        "        api = tweepy.API(auth) \n",
        "  \n",
        "        # 200 tweets to be extracted \n",
        "        number_of_tweets=30\n",
        "        tweets = api.user_timeline(screen_name=username) \n",
        "  \n",
        "        # Empty Array \n",
        "        MyEmptydf =  []\n",
        "  \n",
        "        # create array of tweet information: username,  \n",
        "        # tweet id, date/time, text \n",
        "        tweets_for_csv = [tweet.text for tweet in tweets] # CSV file created  \n",
        "        for j in tweets_for_csv: \n",
        "            \n",
        "            # Appending tweets to the empty array tmp \n",
        "                MyEmptydf.append({ 'real': realname, \n",
        "                                  'tweet': j, 'user': username,\n",
        "                                   'party': party})\n",
        "  \n",
        "        # Printing the tweets \n",
        "        return(pd.DataFrame(MyEmptydf)) \n",
        "        \n",
        "  \n",
        "# Driver code \n",
        "if __name__ == '__main__': # what is this for???\n",
        "  \n",
        "    # Here goes the twitter handle for the user \n",
        "    # whose tweets are to be extracted. \n",
        "    get_tweets('akk', 'Annegreth Kramp-Karrenbauer', 'CDU')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "616GHzBnSoYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_tweets(\"akk\", \"Annegreth Kramp-Karrenbauer\", \"CDU\")  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBwq-sTKTzZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CDU\n",
        "akk = get_tweets(\"akk\",\"Annegreth Kramp-Karrenbauer\", \"CDU\")   \n",
        "merkel = get_tweets(\"AngelaMerkeICDU\", \"Angela Merkel\", \"CDU\") \n",
        "# SPD\n",
        "barley = get_tweets(\"katarinabarley\", \"Katharina Barley\", \"SPD\") \n",
        "nahles = get_tweets(\"AndreaNahlesSPD\", \"Andrea Nahles\", \"SPD\") \n",
        "# Grüne\n",
        "oezdemir = get_tweets(\"cem_oezdemir\", \"Cem Özdemir\", \"Grüne\") \n",
        "ekartd = get_tweets(\"GoeringEckardt\", \"Kathrin Goering-Eckardt\", \"Grüne\") \n",
        "# AfD\n",
        "weidel = get_tweets(\"Alice_Weidel\", \"Alice Weidel\", \"AfD\")\n",
        "meuthen = get_tweets(\"Joerg_Meuthen\", \"Jörg Meuthen\", \"AfD\")\n",
        "# Linke\n",
        "wagenknecht = get_tweets(\"SWagenknecht\", \"Sarah Wagenknecht\", \"Linke\")\n",
        "# FDP\n",
        "lindner = get_tweets(\"c_lindner\", \"Christian Lindner\", \"FDP\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ycPRHP1T-OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = [akk, merkel, barley, nahles, oezdemir, ekartd, weidel, meuthen, wagenknecht, lindner]\n",
        "df = pd.concat(frames, sort=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SssvvLAXaK0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IGqAiWBZkn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('/content/gdrive/My Drive/out.csv', sep=',', encoding='utf-8', index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bdl2-zqXjba",
        "colab_type": "text"
      },
      "source": [
        "Data is now saved but we need to do a bit more cleaning: \n",
        "delete stopwords, Sonderzeichen, Emojis links, name of party etc.\n",
        "we should also decide if we want to take retweets out or include them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "des_C8hEWFLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}